{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Y7X66t-h7EVf",
    "outputId": "8647c7d7-b2cb-4373-bbb8-99942b7d6747"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Google colab link: https://colab.research.google.com/drive/1naZ2DyxELRxfW9-jm1xsbz3pucnLdIaK\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n55yI2bP7F7n"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read data\n",
    "train = pd.read_csv('train-balanced-sarcasm.csv')\n",
    "train = train.dropna(subset = ['comment']) # drop na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLPU6pSv_rhU"
   },
   "outputs": [],
   "source": [
    "# without meta-data\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# for meta-data, same as Logistic Regression and SVM\n",
    "# change to CountVectorizer for experimentation\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range = (1, 2), stop_words = 'english', max_features = 500) \n",
    "one_hot = tfidf_vectorizer.fit_transform(train['comment']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_wqYRCKCAKDh",
    "outputId": "a58456db-2c8f-4189-9ee4-c8018c44a6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1010773, 500)\n"
     ]
    }
   ],
   "source": [
    "print(one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "V4l1Hq-nAQO3",
    "outputId": "84e0aebf-55ff-4a52-f1de-83acceb2748f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1010773,)\n"
     ]
    }
   ],
   "source": [
    "y = np.asarray(train['label'])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1ZBMX0wAQjt"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1001)\n",
    "mask = np.random.rand((len(y))) # for train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EdIDcpyWAabu",
    "outputId": "a77c7320-d022-4e3f-fd49-5c3a3cc8777e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([859133, 500]) torch.Size([151640, 500])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.from_numpy(one_hot[mask <= 0.85])\n",
    "x_test = torch.from_numpy(one_hot[mask > 0.85])\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "V-9TuKOWAamq",
    "outputId": "06c3f9b3-239a-4e41-fb76-dcee69510242"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([859133]) torch.Size([151640])\n"
     ]
    }
   ],
   "source": [
    "y_train = torch.from_numpy(y[mask <= 0.85])\n",
    "y_test = torch.from_numpy(y[mask > 0.85])\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BEDHAQ0Aa1g"
   },
   "outputs": [],
   "source": [
    "train = TensorDataset(x_train, y_train)\n",
    "test = TensorDataset(x_test, y_test)\n",
    "# Data loader\n",
    "train_loader = DataLoader(train, batch_size = 500, shuffle = True)\n",
    "test_loader = DataLoader(test, batch_size = 500, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgRQSgItApx4"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2b9wVCHSAp1x"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "# Neural network architecture\n",
    "# 3 hidden layers, RELU + dropout\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(500, 256), torch.nn.PReLU(), torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(256, 128), torch.nn.PReLU(), torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(128, 64), torch.nn.PReLU(), torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(64, 2), torch.nn.Sigmoid())\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # Loss function\n",
    "lr = 1e-3 # Learning rate\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = lr, weight_decay=1e-3/3) # Adam \n",
    "scheduler = MultiStepLR(optimizer, milestones=[50, 80], gamma = 0.1)\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qD9x2DwvBikg",
    "outputId": "b2233bfa-3c1b-4371-bacb-0e5f2964afb4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 6.480143215908501\n",
      "Epoch: 2, Loss: 6.445178324962114\n",
      "Epoch: 3, Loss: 6.434603117771789\n",
      "Epoch: 4, Loss: 6.426949951606705\n",
      "Epoch: 5, Loss: 6.422431302862383\n",
      "Epoch: 6, Loss: 6.419205835827302\n",
      "Epoch: 7, Loss: 6.416995644720224\n",
      "Epoch: 8, Loss: 6.415138520385714\n",
      "Epoch: 9, Loss: 6.413544275670034\n",
      "Epoch: 10, Loss: 6.411292956093306\n",
      "Epoch: 11, Loss: 6.410623857735356\n",
      "Epoch: 12, Loss: 6.408905699993555\n",
      "Epoch: 13, Loss: 6.4082733277452775\n",
      "Epoch: 14, Loss: 6.408109036915883\n",
      "Epoch: 15, Loss: 6.407991687364124\n",
      "Epoch: 16, Loss: 6.407967179008825\n",
      "Epoch: 17, Loss: 6.406821826889488\n",
      "Epoch: 18, Loss: 6.406744932497103\n",
      "Epoch: 19, Loss: 6.407217373261808\n",
      "Epoch: 20, Loss: 6.405786441844169\n",
      "Epoch: 21, Loss: 6.405873309276453\n",
      "Epoch: 22, Loss: 6.405097994401264\n",
      "Epoch: 23, Loss: 6.4040422501321315\n",
      "Epoch: 24, Loss: 6.403283145002383\n",
      "Epoch: 25, Loss: 6.40342229822102\n",
      "Epoch: 26, Loss: 6.404372771243653\n",
      "Epoch: 27, Loss: 6.403445900850853\n",
      "Epoch: 28, Loss: 6.403101105977742\n",
      "Epoch: 29, Loss: 6.4031695553733865\n",
      "Epoch: 30, Loss: 6.400168663852385\n",
      "Epoch: 31, Loss: 6.402479287807338\n",
      "Epoch: 32, Loss: 6.400951328944701\n",
      "Epoch: 33, Loss: 6.401695694094926\n",
      "Epoch: 34, Loss: 6.4015621240441885\n",
      "Epoch: 35, Loss: 6.4016140726550725\n",
      "Epoch: 36, Loss: 6.40240430476973\n",
      "Epoch: 37, Loss: 6.4025047677968905\n",
      "Epoch: 38, Loss: 6.402269029069004\n",
      "Epoch: 39, Loss: 6.400786602423546\n",
      "Epoch: 40, Loss: 6.399795441132572\n",
      "Epoch: 41, Loss: 6.400820535735159\n",
      "Epoch: 42, Loss: 6.401468531140686\n",
      "Epoch: 43, Loss: 6.400451721619314\n",
      "Epoch: 44, Loss: 6.3994134348529945\n",
      "Epoch: 45, Loss: 6.401361234413144\n",
      "Epoch: 46, Loss: 6.400479294039358\n",
      "Epoch: 47, Loss: 6.400428062446681\n",
      "Epoch: 48, Loss: 6.40052388306713\n",
      "Epoch: 49, Loss: 6.3992936341881945\n",
      "Epoch: 50, Loss: 6.372954977348716\n",
      "Epoch: 51, Loss: 6.36108909610499\n",
      "Epoch: 52, Loss: 6.356231868032909\n",
      "Epoch: 53, Loss: 6.3522830510372765\n",
      "Epoch: 54, Loss: 6.349941158913859\n",
      "Epoch: 55, Loss: 6.348221169948489\n",
      "Epoch: 56, Loss: 6.3457070893887435\n",
      "Epoch: 57, Loss: 6.344192384782852\n",
      "Epoch: 58, Loss: 6.343141706471099\n",
      "Epoch: 59, Loss: 6.340724964862085\n",
      "Epoch: 60, Loss: 6.338135919996701\n",
      "Epoch: 61, Loss: 6.33666393815929\n",
      "Epoch: 62, Loss: 6.334482728879598\n",
      "Epoch: 63, Loss: 6.331174685767941\n",
      "Epoch: 64, Loss: 6.330183926867447\n",
      "Epoch: 65, Loss: 6.328339266231147\n",
      "Epoch: 66, Loss: 6.326418659595194\n",
      "Epoch: 67, Loss: 6.3266715543799235\n",
      "Epoch: 68, Loss: 6.325520109860597\n",
      "Epoch: 69, Loss: 6.323824809979354\n",
      "Epoch: 70, Loss: 6.322174374555228\n",
      "Epoch: 71, Loss: 6.320432510463981\n",
      "Epoch: 72, Loss: 6.320204176067802\n",
      "Epoch: 73, Loss: 6.318321317821472\n",
      "Epoch: 74, Loss: 6.317626898001944\n",
      "Epoch: 75, Loss: 6.317992078115495\n",
      "Epoch: 76, Loss: 6.314903645505046\n",
      "Epoch: 77, Loss: 6.313263141494216\n",
      "Epoch: 78, Loss: 6.314257250642339\n",
      "Epoch: 79, Loss: 6.31287672695756\n",
      "Epoch: 80, Loss: 6.300677189078568\n",
      "Epoch: 81, Loss: 6.297564335528683\n",
      "Epoch: 82, Loss: 6.295970771407935\n",
      "Epoch: 83, Loss: 6.296691272374516\n",
      "Epoch: 84, Loss: 6.294969297126487\n",
      "Epoch: 85, Loss: 6.295509684992514\n",
      "Epoch: 86, Loss: 6.293781671805965\n",
      "Epoch: 87, Loss: 6.291528492907711\n",
      "Epoch: 88, Loss: 6.290647966103929\n",
      "Epoch: 89, Loss: 6.292056927348283\n",
      "Epoch: 90, Loss: 6.2902456880164\n",
      "Epoch: 91, Loss: 6.28994623873454\n",
      "Epoch: 92, Loss: 6.2885418512130045\n",
      "Epoch: 93, Loss: 6.288444752309006\n",
      "Epoch: 94, Loss: 6.286312172612521\n",
      "Epoch: 95, Loss: 6.287349823532505\n",
      "Epoch: 96, Loss: 6.286162076107286\n",
      "Epoch: 97, Loss: 6.284149742133347\n",
      "Epoch: 98, Loss: 6.284794140306743\n",
      "Epoch: 99, Loss: 6.2835943787506086\n",
      "Epoch: 100, Loss: 6.280832140513363\n",
      "Epoch: 101, Loss: 6.281546098125106\n",
      "Epoch: 102, Loss: 6.2788049274576725\n",
      "Epoch: 103, Loss: 6.2777593563830125\n",
      "Epoch: 104, Loss: 6.2767605000678985\n",
      "Epoch: 105, Loss: 6.275184662288431\n",
      "Epoch: 106, Loss: 6.2741806498249675\n",
      "Epoch: 107, Loss: 6.272925880796529\n",
      "Epoch: 108, Loss: 6.272037893812015\n",
      "Epoch: 109, Loss: 6.2706377130054305\n",
      "Epoch: 110, Loss: 6.268137230121892\n",
      "Epoch: 111, Loss: 6.268161738824079\n",
      "Epoch: 112, Loss: 6.265415312798231\n",
      "Epoch: 113, Loss: 6.263261198273333\n",
      "Epoch: 114, Loss: 6.262140472451334\n",
      "Epoch: 115, Loss: 6.259653805436771\n",
      "Epoch: 116, Loss: 6.260396021266814\n",
      "Epoch: 117, Loss: 6.258424419616035\n",
      "Epoch: 118, Loss: 6.256227745360179\n",
      "Epoch: 119, Loss: 6.255062111373131\n",
      "Epoch: 120, Loss: 6.25394070911886\n",
      "Epoch: 121, Loss: 6.2516351989918775\n",
      "Epoch: 122, Loss: 6.248510086407905\n",
      "Epoch: 123, Loss: 6.247281404423621\n",
      "Epoch: 124, Loss: 6.2451660220636915\n",
      "Epoch: 125, Loss: 6.243845788960699\n",
      "Epoch: 126, Loss: 6.243169402825524\n",
      "Epoch: 127, Loss: 6.241511286946568\n",
      "Epoch: 128, Loss: 6.2400337469172165\n",
      "Epoch: 129, Loss: 6.238730064204017\n",
      "Epoch: 130, Loss: 6.236552006404933\n",
      "Epoch: 131, Loss: 6.234048810854542\n",
      "Epoch: 132, Loss: 6.232505403319492\n",
      "Epoch: 133, Loss: 6.232553055024456\n",
      "Epoch: 134, Loss: 6.229681057846201\n",
      "Epoch: 135, Loss: 6.22693827137286\n",
      "Epoch: 136, Loss: 6.226334121960273\n",
      "Epoch: 137, Loss: 6.222484271168595\n",
      "Epoch: 138, Loss: 6.223945377015748\n",
      "Epoch: 139, Loss: 6.221422536484645\n",
      "Epoch: 140, Loss: 6.218675257807246\n",
      "Epoch: 141, Loss: 6.217014100411287\n",
      "Epoch: 142, Loss: 6.217060843962566\n",
      "Epoch: 143, Loss: 6.213837613663529\n",
      "Epoch: 144, Loss: 6.2131611241556275\n",
      "Epoch: 145, Loss: 6.2139371931660765\n",
      "Epoch: 146, Loss: 6.209294526288465\n",
      "Epoch: 147, Loss: 6.207992003569889\n",
      "Epoch: 148, Loss: 6.207888518104585\n",
      "Epoch: 149, Loss: 6.204778322066304\n",
      "Epoch: 150, Loss: 6.202909560321621\n",
      "Epoch: 151, Loss: 6.202723135934533\n",
      "Epoch: 152, Loss: 6.20019635024229\n",
      "Epoch: 153, Loss: 6.199515130564926\n",
      "Epoch: 154, Loss: 6.198138849324597\n",
      "Epoch: 155, Loss: 6.194488436783131\n",
      "Epoch: 156, Loss: 6.192162184120715\n",
      "Epoch: 157, Loss: 6.189113159760617\n",
      "Epoch: 158, Loss: 6.1895135896270475\n",
      "Epoch: 159, Loss: 6.185766320656536\n",
      "Epoch: 160, Loss: 6.185510370479271\n",
      "Epoch: 161, Loss: 6.181695543963049\n",
      "Epoch: 162, Loss: 6.180083770632446\n",
      "Epoch: 163, Loss: 6.177066304439467\n",
      "Epoch: 164, Loss: 6.176081312210808\n",
      "Epoch: 165, Loss: 6.173046322953119\n",
      "Epoch: 166, Loss: 6.170610490690967\n",
      "Epoch: 167, Loss: 6.16985125096854\n",
      "Epoch: 168, Loss: 6.169746895507268\n",
      "Epoch: 169, Loss: 6.162732083679959\n",
      "Epoch: 170, Loss: 6.163459512353663\n",
      "Epoch: 171, Loss: 6.161931207643346\n",
      "Epoch: 172, Loss: 6.161397203910407\n",
      "Epoch: 173, Loss: 6.1559049727888455\n",
      "Epoch: 174, Loss: 6.1568380660116535\n",
      "Epoch: 175, Loss: 6.152840369326317\n",
      "Epoch: 176, Loss: 6.150880060625586\n",
      "Epoch: 177, Loss: 6.147663336911223\n",
      "Epoch: 178, Loss: 6.14751075529789\n",
      "Epoch: 179, Loss: 6.143529486203874\n",
      "Epoch: 180, Loss: 6.14397391365345\n",
      "Epoch: 181, Loss: 6.140800885382483\n",
      "Epoch: 182, Loss: 6.1393641023053656\n",
      "Epoch: 183, Loss: 6.137768522763338\n",
      "Epoch: 184, Loss: 6.135526255584841\n",
      "Epoch: 185, Loss: 6.132888877032008\n",
      "Epoch: 186, Loss: 6.131250075202284\n",
      "Epoch: 187, Loss: 6.128279028219983\n",
      "Epoch: 188, Loss: 6.128769885633774\n",
      "Epoch: 189, Loss: 6.128058250092607\n",
      "Epoch: 190, Loss: 6.126606003773767\n",
      "Epoch: 191, Loss: 6.124720442573459\n",
      "Epoch: 192, Loss: 6.123950142316175\n",
      "Epoch: 193, Loss: 6.121040952810311\n",
      "Epoch: 194, Loss: 6.120788189843153\n",
      "Epoch: 195, Loss: 6.11776659949465\n",
      "Epoch: 196, Loss: 6.115832640085661\n",
      "Epoch: 197, Loss: 6.114690431815389\n",
      "Epoch: 198, Loss: 6.112374504631429\n",
      "Epoch: 199, Loss: 6.112308581276707\n",
      "Epoch: 200, Loss: 6.112599521040594\n"
     ]
    }
   ],
   "source": [
    "train_len = x_train.shape[0]\n",
    "losses = [] # to plot losses\n",
    "for epoch in range(epochs):\n",
    "    scheduler.step()\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        net.to(device)\n",
    "        inputs, labels = inputs.float(), labels.long()\n",
    "        inputs = inputs.to(device) # move to GPU\n",
    "        labels = labels.to(device)\n",
    "        #clear grads\n",
    "        optimizer.zero_grad()\n",
    "        #forward to get predicted values\n",
    "        outputs = net.forward(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        # back props \n",
    "        optimizer.step()\n",
    "        # update the parameters\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    loss_ = running_loss / (train_len / 5000)\n",
    "    print('Epoch: {}, Loss: {}'.format(epoch + 1, loss_))\n",
    "    losses.append(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "colab_type": "code",
    "id": "PrRWFoYyBiuW",
    "outputId": "db8771ba-81c1-4471-8363-eba305cefdb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(len(losses)) # sanity check\n",
    "epochs_ = []\n",
    "for i in range(1, 201): # 200 epochs\n",
    "    epochs_.append(i)\n",
    "print(len(epochs_)) # sanity check\n",
    "print()\n",
    "plt.plot(epochs_, losses)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "E13oBTlRBi7v",
    "outputId": "3d3d487f-e457-4431-a35c-6df889e2c90e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed-forward Neural Network for TF-IDF vectorization:\n",
      "Training accuracy:  67.66495990725534\n",
      "Precision:  0.723756954948739  | Recall:  0.5714032972200366  | F1-score:  0.6386192129524235\n",
      "Confusion matrix values: \n",
      "TP:  245460 , FN:  184114 , FP:  93687 , TN:  335872\n"
     ]
    }
   ],
   "source": [
    "# Performance on train set\n",
    "with torch.no_grad():\n",
    "    correct, total = 0, 0\n",
    "    tp, fp, fn, tn = 0, 0, 0, 0 # for confusion matrix\n",
    "    for i, data in enumerate(train_loader, 0): \n",
    "        inputs, labels = data \n",
    "        net.to(device) \n",
    "        inputs, labels = inputs.float(), labels.long()\n",
    "        inputs = inputs.to(device) # move to GPU\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # true positives\n",
    "        tp += (predicted[labels == 1] == labels[labels == 1]).sum().item()\n",
    "        # false negatives\n",
    "        fn += (predicted[labels == 1] != labels[labels == 1]).sum().item()\n",
    "        # false positives\n",
    "        fp += (predicted[labels == 0] != labels[labels == 0]).sum().item()\n",
    "        # true negatives\n",
    "        tn += (predicted[labels == 0] == labels[labels == 0]).sum().item()\n",
    "        precision = (tp / (tp + fp))\n",
    "        recall =  (tp / (tp + fn))\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Feed-forward Neural Network for TF-IDF vectorization:\")\n",
    "print(\"Training accuracy: \", (100 * correct) / total)\n",
    "print(\"Precision: \", precision, \" | Recall: \", recall, \" | F1-score: \", f1)\n",
    "print(\"Confusion matrix values: \")\n",
    "print(\"TP: \", tp, \", FN: \", fn, \", FP: \", fp, \", TN: \", tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "qlngBOLaAQui",
    "outputId": "35b22f70-f644-4d19-db6a-4de8ec39dd18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:  65.54009496175152\n",
      "Precision:  0.6851977152208463  | Recall:  0.574517771855292  | F1-score:  0.6249955147296279\n",
      "Confusion matrix values: \n",
      "TP:  43545 , FN:  32249 , FP:  20006 , TN:  55840\n"
     ]
    }
   ],
   "source": [
    "# Performance on test set\n",
    "with torch.no_grad():\n",
    "    correct, total = 0, 0\n",
    "    tp, fp, fn, tn = 0, 0, 0, 0 # for confusion matrix\n",
    "    for i, data in enumerate(test_loader, 0): \n",
    "        inputs, labels = data \n",
    "        net.to(device) \n",
    "        inputs, labels = inputs.float(), labels.long()\n",
    "        inputs = inputs.to(device) # move to GPU\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # true positives\n",
    "        tp += (predicted[labels == 1] == labels[labels == 1]).sum().item()\n",
    "        # false negatives\n",
    "        fn += (predicted[labels == 1] != labels[labels == 1]).sum().item()\n",
    "        # false positives\n",
    "        fp += (predicted[labels == 0] != labels[labels == 0]).sum().item()\n",
    "        # true negatives\n",
    "        tn += (predicted[labels == 0] == labels[labels == 0]).sum().item()\n",
    "        precision = (tp / (tp + fp))\n",
    "        recall =  (tp / (tp + fn))\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Testing accuracy: \", (100 * correct) / total)\n",
    "print(\"Precision: \", precision, \" | Recall: \", recall, \" | F1-score: \", f1)\n",
    "print(\"Confusion matrix values: \")\n",
    "print(\"TP: \", tp, \", FN: \", fn, \", FP: \", fp, \", TN: \", tn)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FeedForward_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
